% !TEX encoding = UTF-8 Unicode
% !TEX TS-program = LuaLaTeX
\documentclass[
	DIV=calc,
	BCOR=0mm,
	pagesize,
]{scrartcl}
% [headinclude] includes header in Satzspiegelberechnung
% [headlines] gives vsize of header, default is 1.25
% [pagesize] ensures compatibility with PDF and DVI

%*****************PACKAGES IN USE******************
\usepackage{fourier}  % use Fourier for maths
\usepackage{ttjenevers}  % use TT Jenevers for rm
\usepackage{ttcommons}  % use TT Commons for sf
\setmonofont[Scale=MatchLowercase]{Envy Code R}  % use Envy Code R for tt
\usepackage[defaultlines=2,all]{nowidow}  % prevent widow and orphan lines
\usepackage{graphicx}  % required to insert images
\usepackage[usenames,dvipsnames]{xcolor}  % required for custom colours
\usepackage{amsmath,amssymb}  % better maths support & more symbols
\usepackage{microtype}  % improved typography
\usepackage[singlespacing]{setspace}  % improved linespacing
\usepackage{url}  % typeset url's
\usepackage{lipsum}  % blind text
\usepackage{tabularx}  % more spacing options for tables
\usepackage{booktabs}  % improved tables
\usepackage{enumitem}  % enumerate environment, custom list labels
\usepackage{pgfplots}  % plot plots
	\pgfplotsset{compat=1.15}  % newest version
	\usepgfplotslibrary{groupplots}  % to group plots, surprisingly
\usepackage{localextra}  % provides hyphenation for linguistic terms, names, etc.
\usepackage{natbib}  % use Harvard citation style
	\bibliographystyle{newharvard}
%**************************************************

%*******************KOMA-Options*******************
% \KOMAoptions{parskip=half,headsepline,footsepline}  % example use
% [parskip=half] separates subsections by 0.5 lines
% [headsepline,headtopline,footsepline] put lines after header & before footer <-- does NOT work with \pagestyle{plain.scrheadings}
%**************************************************

%**************Customise Font Formats**************
% \addtokomafont{pageheadfoot}{\sffamily\upshape}  % example use
% \setkomafont{author}{\sffamily\footnotesize}  % example use
\addtokomafont{author}{\sffamily\addfontfeature{Style=Alternate}}
\setkomafont{disposition}{\ttcdemibold}
\addtokomafont{caption}{\footnotesize}
% Elements on page 60 of (German) KOMA manual
%**************************************************

\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\abm}{\textsc{abm}}
\newcommand{\lsg}{\textsc{lsg}}
\newcommand{\nslsg}[1]{\textit{#1}-state/\textit{#1}-term \lsg}
\newcommand{\odd}{\textsc{odd}}
\newcommand{\dash}{â€“}

\title{Influencing convergence speed in Lewis signalling games}
\author{Marcel Ruland}
\date{hand-in date: \today}  % omit date

\begin{document}
\maketitle
\tableofcontents

\section{Introduction}
\label{sec:int}
\emph{Lewis signalling games} (henceforth \lsg) were first introduced by \citet{lewis_convention_1969}.
Following \citet[p.~530~ff.]{barrett_dynamic_2007}, they works as follows:
There is a set of states of the world \(S\), a set of signals (or terms) \(T\), and a set of acts \(A\).
There is a mapping from acts to states of the world, such that every act corresponds to a state of the world.\footnote{\citet{barrett_dynamic_2007} leaves unclear if that mapping must be bijective (for every \(a\) there is exactly one corresponding \(s\) and for every \(s\) there is at least one corresponding \(a\)), but every signalling game involved in this essay fulfils this condition.}
There is a \emph{sender}, who can observe the current state of the world and a \emph{receiver,} who cannot observe the current state of the world.
In each round exactly one state of the world \(s \in S\) holds, i.e.~is the current state of the world.
The sender will observe the current state of the world and then choose a signal \(t \in T\) and send it to the receiver.
The receiver will observe the signal and then perform an act \(a \in A\).
A round is won if the act \(a\) matches the current state of the world \(s\) and lost if it does not.
Both sender and receiver know about whether the round was a success or a failure and adapt their strategies for choosing signals and acts according to some learning function.
Commonly, states of the world are distributed uniformly and sender and receiver start out with randomly choosing a signal and an act respectively, but this is not a formal requirement for the game to count as an \lsg.

\emph{Agent-based modelling} (henceforth \abm) is a modelling paradigm that has its roots in cellular automata and complexity theory \citep{heath_some_2014}.
Following \citet{grimm_individual_2005,railsback_agent_2011} in an \abm, there are individual \emph{agents} representing individual entities of one or several kinds (such as for instance cars, sheep, or viruses).
These entities interact with each other, with an \emph{environment,} or (typically) both.
The environment itself has characteristics which influence the agents.
It can play a major role in the simulation (such as a forest providing food and shelter to a population of animals) or be virtually inexistent (as is the case in the present essay, see section~\ref{sec:mod}).
Typical applications include (but are by far not limited to) the simulation of traffic flow in a road network, spreading of a virus in a population (human or non-human), and changes in real estate prices in a city.
The strength of \abm, in comparison to other modelling paradigms, is that  by modelling each individual agent, one can observe how the sum of individual actions of agents give rise to phenomena which were not explicitly programmed into the model (such as the creation of ant corridors, which are not intentionally created by any individual ant, but are a byproduct of the fact that ants directly follow each other in straight lines, \citet{wilensky_netlogo_1997}).

This essay combines both paradigms.
An \abm\ will be created where there is a population of senders and a population of receivers.
Initially the number of signals available will be less than the number of states of the world and actions, but will be increased with time.
The aim is to determine how the time at or the condition on which more symbols will be made available influences the speed of convergence towards \emph{perfect communication.}
Perfect communication in an \lsg\ is achieved if ``each state of the world corresponds to a term in the language and each term corresponds to an act that matches the state of the world, so each signal leads to a successful action'' \citep[p.~530, there referred to as ``perfect Lewis signalling system'']{barrett_dynamic_2007}.
The model, described in detail in section \ref{sec:mod}, has some functionality for choosing parameters which will not be used in this essay, for simple reasons of scope.


\section{Model description}
\label{sec:mod}
The description of the model follows the \emph{Overview, Design concepts, and Details} protocol \citep[][henceforth \odd]{grimm_standard_2006, grimm_odd_2010}.

\subsection{Purpose}
\label{ssec:modpur}
The model is run to understand how, based on elapsed time and/or quality of communication, increasing the number of symbols available in an \lsg\ accelerates or slows down convergence towards perfect communication.

\subsection{Entities, state variables, and scales}
\label{ssec:modent}
There are two entities, \code{senders} and \code{receivers}, the populations of which are equal in size.
The \code{senders} have two state variables.
\code{urns} is a list of integer lists for implementing the urns in an urn learning function, see subsubsection \ref{sssec:moddeslea}.
Every nested list represents one urn, the integers within it represent balls to be drawn from it.
\code{chosen-signal} is an integer corresponding to the signal the sender will send in the current round.
\code{receivers} are structured almost identically.
The urns are also lists of integer lists, but are structured differently (see again subsubsection \ref{sssec:moddeslea}).
Instead of a \code{chosen-signal} variable, they have a \code{chosen-action} variable.
In addition, they also have a \code{received-signal} variable, which stores the signal received from a sender.
Senders and receivers are connected by \code{links}, which carry a signal in their \code{signal} variable.
This \code{signal} variable can be read only by the sender and the receiver corresponding to the link.
The environment is simply a state of the world, implemented as a global integer variable, and nothing else.
The following parameters of the model can be modified:
\begin{itemize}
	\item number of possible states of the world (the number of possible actions is always equal to this value)
	\item number of available signals
	\item population size (equal for senders and receivers)
	\item number of balls added in case of success
	\item number of balls removed in case of failure
\end{itemize}

\subsection{Process overview and scheduling}
\label{ssec:modpro}
Every iteration begins with randomly choosing a state of the world and creating a randomised one-to-one mapping from senders to receivers.
Links are then created and connected to senders and receivers according to this mapping.
Senders have access to the state of the world and choose a signal based on it, which they then pass on to their respective link.
Once the links carry the sent signal, receivers have access to it and read it.
They choose an action based on the received signal and check whether the action matches the state of the world.
Receivers then pass on an arbitrary, conventional value (here 42) on to the links, which the receivers can read and interpret as \emph{success.}
Lastly, senders and receivers run a learning function according to whether the round was a success or a failure.

The reader will notice that the previous paragraph seems to contradict the above given definition for an \lsg.
Receivers cannot observe the state of the world, yet in this model description it is the receivers who check whether their performed action corresponds to the current state of the world.
While this may seem a violation of the rules of an \lsg, it is in fact not.
Once signals and actions have been chosen, the simplest way of implementing the passing on of the correct success/failure information to the correct senders/receivers just happened to be letting the receivers check the global state of the world variable and then informing the correct senders via the still-existent links.
At no other time do the receivers access the state of the world variable, thus not violating the definition of an \lsg.
 

\subsection{Design concepts}
\label{ssec:moddes}
\paragraph{Emergence}
The number one (and only) emergent behaviour predicted here is that of perfect communication.
From an initially random distribution of chosen signals and chosen actions emerges (ideally) a perfect one-to-one mapping from states of the world to signals and to actions corresponding to the states of the world.
\paragraph{Adaptation}
Senders have as many urns as there are possible states of the world.
Receivers have as many urns as there are available signals.
A sender chooses a signal by randomly drawing a ball from the urn corresponding to the current state of the world.
A receiver chooses an action by randomly drawing a ball from the urn corresponding to the received signal.

\paragraph{Objectives}
Senders and receivers aim to maximise the percentage of rounds in which communication is successful, i.e.~in which the current state of the world matches the action chosen by the receiver.

\paragraph{Learning}
Senders start off with one ball corresponding to every possible signal in each of their urns.
In a game with three possible states of the world and two available signals, the initial configuration will look like this: \code{[[0 1] [0 1] [0 1]]}
Receivers start off with one ball corresponding to every possible action in each of their urns.
In the same game, their initial urn configuration looks as follows: \code{[[1 2 3] [1 2 3]]}
In case of success, senders and receivers will add more balls with the chosen signal/action to the consulted urn.
In case of failure, they will remove balls with the chosen signal/action.
The number of added or removed balls is determined by the value of two parameters.

\paragraph{Prediction}
Agents cannot predict the future values of any variables.

\paragraph{Stochasticity}
The state of the world of a round is determined by randomly drawing a value from a uniform distribution.
Furthermore, within one of the steps described in subsection \ref{ssec:modpro}, the order in which senders and receivers perform their actions is also randomised.

\paragraph{Observation}
A game is considered to converge to perfect communication if \emph{the moving average (mean) of communication quality over the past 1000 rounds is > 0.8 for 100 consecutive rounds.}
If this criterion is not met within one million rounds, then the game is considered to have failed to converge.
The 0.8 threshold is in line with \citet[p.~533]{barrett_numerical_2006, barrett_dynamic_2007}.
In \citet[sec.~2, unpaginated preprint]{barrett_numerical_2006}, the author states that ``After 10\textsuperscript{6} plays the ratio of successful actions to the number of plays, the signal success rate, is typically better than 0.999'', but leaves open how this is measured.
In trial runs, the condition of 100 consecutive rounds has proven to be a reliable indicator for convergence and has therefore been chosen.

\subsection{Initialisation}
\label{ssec:modini}
The model is initialised by creating a population, setting the number of available actions equal to the number of possible world states, and resetting the counter keeping track of the number of rounds played.

\section{Results}
\label{sec:res}
The results section is focused on two main questions.
The most obvious one, and the focus of subsection \ref{ssec:respop} is how population size influences convergence speed in an \lsg, as this parameter is the main novelty that \abm\ brings to the game.
A second question is the introduction of signals into an ongoing game.
Subsection \ref{ssec:resint} investigates how beginning a game with just one signal, and then introducing more signals as the rounds progress, influences convergence speed.

\subsection{Population size}
\label{ssec:respop}
In the first experiment, to investigate the effect of population size on convergence speed, the model was run with the following parameter settings:
\begin{verbatim}
num-signals = 10
num-remove-balls = 1
num-add-balls = 5
num-world-states = 10
\end{verbatim}
\code{population-size} was incremented step-wise from 1, 2, 3, \ldots, 98, 99, 100 and ten runs were performed for every value.\footnote{10 runs are, admittedly, less than one would have liked given the extent of variation shown in figure ref{fig:pop}; unfortunately the complexity of running the model with high values of population-size was such that e.g. 100 runs for every value were just not feasible.}

The value for \code{num-add-balls} may seem unusually high.
Small populations tend to not converge if the value for this parameter is too high, whereas large populations tend to not converge if it is too low.
Assigning a value of 5 to \code{num-add-balls} has proven to reliably lead to convergence with smaller and larger populations.
In fact, out of the one thousand runs for this experiment, only four runs did not converge within one million iterations.
The respective population sizes were 3, 4, 12, and 48.

The predicted result here is that with increasing population size the number of iterations until convergence will also increase.
If a given sender and a given receiver are paired in the random mapping and communicate successfully, then they will adapt their strategies only to each other.
This is not an issue if population size is equal to one, because the same sender and receiver will be paired over and over again.
But as population size increases, the likelihood of being paired with the same sender/receiver decreases and therefore iterations are needed not only for convention to emerge within a single pair but within many pairs and eventually across an entire population.

Figure \ref{fig:pop} shows the mean and median convergence speed for all values of \code{population-size} respectively.
One can see that the mean values consistently are at least as high, but usually higher, than their median counterparts.
This indicates rare runs with very late convergence, increasing the means more than the medians.\footnote{All other experiments have shown similar characteristics with rare, high outliers. I have therefore decided to only consider medians as a measure of centrality from now on, which are much less affected by outliers as compared to means.}
Visually, the plot seems to affirm the predicted statistical relationship between the two variables and indeed there appears to be a correlation of R\textsuperscript{2}~=~0.55.
One would obviously expect this relation to be logarithmic, because for every pair added to the population the population grows by a factor of \(\frac{1}{n+1}\), but the simulation is not nearly extensive enough to affirm or deny this hypothesis.

\begin{figure}
	\centering
	\begin{tikzpicture}
		\begin{axis}[
				xlabel={population size},
				ylabel={iterations until convergence},
				legend entries={mean, median},
				ymax=10800,
			]
			\addplot+[mark=none, color=lightgray] table {../data/population_size_mean.dat};
			\addplot+[mark=none, color=blue] table {../data/population_size_median.dat};
		\end{axis}
	\end{tikzpicture}
	\caption{Effect of population size on convergence speed; x-axis indicates population size, y-axis indicates mean and median number of iterations until convergence to perfect communication; the outlier not in view for a population size of 42 has a value of 14450; R\textsuperscript{2}~=~0.55.}
	\label{fig:pop}
\end{figure}

\subsection{Introducing signals into an ongoing \lsg}
\label{ssec:resint}
\subsubsection*{Macro scale}
A second experiment is concerned with the effects of delaying the introduction of signals into the game. The model was run with the following parameter settings:
\begin{verbatim}
population-size = 10
num-remove-balls = 1
num-add-balls = 3
num-world-states = 10
\end{verbatim}
The number of available signals at the beginning of a game was always 1.
More signals were then introduced after a certain amount of iterations\dash given by the parameter \code{signals-interval}\dash had passed.
The values tested for \code{signals-interval} were 100, 200, 300, \ldots, 4000, 4100, 4200.
For every value, 100 runs were performed.

Figure~\ref{fig:sigmacro} shows a somewhat dull linear relationship (R\textsuperscript{2}~=~0.97).
This is, in hindsight, no surprise as figure~\ref{fig:pop} shows a convergence median of 4585 rounds for a population of size 10.
Introducing signals to the game long after the 4585\textsuperscript{th} round has passed is bound to slow convergence down.
The linear relationship one can see here is simply representing the linear fashion in which the value of \code{signals-interval} has been increased.
A truly interesting result would be a later introduction of signals that speeds up median convergence speed, instead of slowing it down.
In order to potentially produce such results it is necessary to zoom in and choose much smaller values for \code{signals-interval}.

\begin{figure}
	\centering
	\begin{tikzpicture}
		\begin{axis}[
				xlabel={\# of rounds between signal introductions},
				ylabel={iterations until convergence},
			]
			\addplot+[mark=none] table {../data/plc_lsg-adding-signals-big-table_medians.dat};
		\end{axis}
	\end{tikzpicture}
	\caption{Effect of later signal introduction on convergence speed; x-axis indicates the number of iterations that passed before another signal was introduced; y-axis indicates the median number of iterations until convergence; R\textsuperscript{2}~=~0.97}
	\label{fig:sigmacro}
\end{figure}

But all is not lost.
Figure~\ref{fig:com} shows how communication quality evolved along on of the games played as part of the second experiment, and brings much less expected results to light.
In the game displayed, a new signal was introduced every 4200 rounds.
One can see that communication quality remains close to 0.1 without significant variation up until around the 25000\textsuperscript{th} iteration.
Around this iteration, communication quality experiences a sudden increase.

\begin{figure}
	\centering
	\begin{tikzpicture}
		\begin{axis}[
				xlabel={iteration},
				ylabel={communication quality},
				legend entries={n~=~100, n~=~1000},
				legend pos=north west,
				ymax=1.14,
			]
			\addplot+[mark=none, very thin, color=lightgray] table {../data/plc_lsg_jump_4200_n100_simplified.dat};
			\addplot+[mark=none, thick, color=blue] table {../data/plc_lsg_jump_4200_n1000_simplified.dat};
			\addplot+[nodes near coords, only marks, no marks, point meta=explicit symbolic, color=black] table [meta=label] {
				x	y	label
				0	0.45	\(1\)
				4200	0.45 \(2\)
				8400	0.45 \(3\)
				12600	0.45 \(4\)
				16800	0.45 \(5\)
				21000	0.45 \(6\)
				25200	0.45 \(7\)
				29400	0.45 \(8\)
				33600	0.45 \(9\)
				37800	0.45 \(10\)
			};
			\draw [help lines, dashed]
				(0,0) -- (0,1)
				(4200,0) -- (4200,1)
				(8400,0) -- (8400,1)
				(12600,0) -- (12600,1)
				(16800,0) -- (16800,1)
				(21000,0) -- (21000,1)
				(25200,0) -- (25200,1)
				(29400,0) -- (29400,1)
				(33600,0) -- (33600,1)
				(37800,0) -- (37800,1);
		\end{axis}
	\end{tikzpicture}
	\caption{Communication quality in a game where new signals were introduced with a frequency of 1 signal per 4200 rounds played; x-axis indicates iterations, y axis indicates communication quality; grey line indicates a moving average over 100 rounds, red line a moving average over 1000 rounds; vertical dashed lines indicate when new signals were introduced; for simplicity only values for every 10\textsuperscript{th} round are shown. Notice how communication quality lingers somewhere around 0.1 until the seventh signal is introduced, where it suddenly increases dramatically.}
	\label{fig:com}
\end{figure}


\subsubsection*{Micro scale}
The model was run with the following parameters:
\begin{verbatim}
population-size = 1
num-remove-balls = 1
num-add-balls = 2
num-world-states = 10
\end{verbatim}
\code{signals-interval} was again increased step-wise, but this time on much smaller scales.
First, from 1 to 100, with 100 runs being performed for every value.
Second, from 1 to 10, with 1000 runs being performed for every value.
The results are plotted in figure~\ref{fig:sigmicro} on the left and right respectively.
On the left-hand plot, a linear relation between signal introduction and convergence speed is once again visible.
Statistics confirm this visual hunch with R\textsuperscript{2}~=~0.76.
The right-hand plot shows a somewhat more interesting picture.
The increase in convergence time experiences a drop for \code{signals-interval~=~7} that even goes below the convergence speed for \code{signals-interval~=~0} (i.e.~all signals are available from the beginning of the game on).
Unfortunately, testing the distribution of convergence speeds with \code{signals-interval~=~7} for significantly low values against the distribution with \code{signals-interval~=~0} results in p~=~1.0 with both a Student-t test and a Wilcoxon signed-rank test (the latter does not assume the data to be normally distributed; for the data to be in fact pass tests of normality, e.g.~Shapiro-Wilk, one would have to exclude several high outliers).

\begin{figure}
	\centering
	\begin{tikzpicture}
		\begin{groupplot}[
			group style={
				group size=2 by 1,
	            xlabels at=edge bottom,
	            ylabels at=edge left,
				horizontal sep=1.5cm,
			},
			width=0.5\textwidth,
			xlabel={\code{signals-interval}},
			ylabel={rounds until convergence},
		]
			\nextgroupplot
				\addplot+[mark=none] table {../data/plc_lsg-adding-signals-small-table_medians.dat};
			\nextgroupplot
				\addplot+[mark=none] table {../data/plc_lsg-adding-signals-tiny-table_medians.dat};
		\end{groupplot}
	\end{tikzpicture}
	\caption{Effects of later introduction of signals on a micro scale; x-axis indicates value of \code{signals-interval}, y-axis indicates median iterations until convergence to perfect communication. \emph{Left:} \code{signals-interval} incremented from 0 to 100 with 100 rounds played per value (a value of 0 indicating all signals being available from the beginning on), R\textsuperscript{2}~=~0.76. \emph{Right:} \code{signals-interval} incremented from 1 to 10 with 1000 rounds played per value, R\textsuperscript{2}~=~0.04.}
	\label{fig:sigmicro}
\end{figure}


\subsection{Reproducing \citepos{barrett_numerical_2006} results}
\label{ssec:resrep}
Reproducing existing (and potentially widely established) results is always a desirous endeavour in empirical science.
The present essay is by far not the first simulation approach to \lsg s, so this section aims to reproduce (or fail to reproduce) results existing in the literature.

In \citet{barrett_numerical_2006}, the author introduces the notion of an \nslsg{n}, in which there are \textit{n} possible states of the world and \textit{n} possible actions the receiver may take.
Via simulation, \citeauthor{barrett_numerical_2006} shows that \nslsg{2} always converge to perfect communication (strictly speaking a ratio of 0.999 converges), but that the the same is not true for \nslsg{3}s, \nslsg{4}s, and \nslsg{8}s.
In his experiments, \citeauthor{barrett_numerical_2006} ran one thousand games each and then calculated the ratio of games that had converged to perfect communication.
Table~\ref{tab:nstate} shows \citeauthor{barrett_numerical_2006}'s results compared to mine.
While the results are identical for \nslsg{2}, the same is not true for other values of \textit{n.}
In an effort to rule out chance as a possible cause for these vast discrepancies, I have rerun the experiment for \nslsg{2}s and performed 20000 games.
But even this second, much longer, rerun resulted in a ratio of 0.9735 of games converging to perfect communication.

\begin{table}
	\centering
	\begin{tabular}{l>{\addfontfeature{Numbers=Tabular}}c>{\addfontfeature{Numbers=Tabular}}c}
		\toprule
		model & \multicolumn{2}{c}{success rate}\\
		\cmidrule(lr){2-3}
		& \citeauthor{barrett_numerical_2006} & mine \\
		\midrule
		2-state/2-term & 0.999 & 0.999 \\
		3-state/3-term & 0.096 & 0.974 \\
		4-state/4-term & 0.219 & 0.933 \\
		8-state/8-term & 0.594 & 1.000 \\
		\bottomrule
	\end{tabular}
	\caption{Percentage of games leading to convergence in an \nslsg{n} with 1000 games played per run.}
	\label{tab:nstate}
\end{table}

The other possible cause that comes to mind are subleties in the definition of convergence to perfect communication.
\citet[sec.~2, unpaginated preprint]{barrett_numerical_2006} writes, that ``[o]ut of 10\textsuperscript{3} runs, there were three where the success rate was less than 0.8 after 10\textsuperscript{6} plays'' and further that ``[t]here are 10\textsuperscript{6} plays/run here, and a run is taken to fail to converge if the final signal success rate of the run is less than 0.8.''
This leaves some room open for interpretation however.

If \citeauthor{barrett_numerical_2006}'s words are to be taken literally, then the measure of convergence takes into account only the one millionth round and ignores everything that happened beforehand.
But the variance of communication quality in between rounds is vast.
In figure~\ref{fig:com}, the light grey line indicates a moving average over the past one hundred rounds played.
Yet even this moving average shows drastic fluctuations, especially towards convergence where fluctuations reach an amplitude of about 0.1.
A closer look at games failing to converge shows that this fluctuation does not stop, not even decrease, as the rounds progress.
And again, the fluctuations visible in figure~\ref{fig:com} are of a moving average over the past one hundred rounds.
The fluctuations in communication quality in each individual round are undoubtedly much higher.
It therefore seems unreasonable that \citeauthor{barrett_numerical_2006} defines convergence in such a way that only a single round is taken into account.
Chance would drastically influence the ratio of games converged, and this is surely not a desired characteristic for a metric.
It could, however, potentially explain the much lower values of \citeauthor{barrett_numerical_2006}'s experiments.
Many games that would be ruled out by chance when considering only a single round would pass the convergence test when looking at a moving average over the past one thousand rounds, as was the case in the present essay (for the precise definition employed here, see subsection~ref{ssec:moddes}, paragraph on observation).

There is one more subtlety that needs to be mentioned here.
For the experiments in table~\ref{tab:nstate} only, I have considered games as non-convergent if they had not converged by the 100000\textsuperscript{th} iteration; the simple reason being the amount of time the simulations took.
But this cannot be the cause of the discrepancy for two reasons:
First off, the amount of games ``incorrectly'' classified as non-convergent is in all probability very low.
The median convergence time for all \nslsg s run is below two thousand, with no game having converged after more than thirty thousand iterations.
Secondly, \emph{if} a game has been incorrectly classified as non-convergent, then this would of course distort the data but it would result in values \emph{lower} than the ones I was supposed to obtain.
In other words, if at all influenced by substituting one hundred thousand for one million, then this inaccuracy has decreased the gap in table~\ref{tab:nstate}, not increased it.
Therefore, it cannot possibly be an explanation for it.

Nevertheless, despite the different ratios the key findings of \citet{barrett_numerical_2006} have been replicated.
It is the case that \nslsg{2}s converge with a ratio of 0.999 and it is the case that \nslsg{n}s with \textit{n} > 2 do converge in some cases but do not converge in others.
Another conclusion of \citet[sec.~2, unpaginated preprint]{barrett_numerical_2006} has also been reproduced: ``While failures to approach signaling systems were observed, each system always learned to do better than chance in signaling, and hence might be said to have developed a more or less effective language.''
While the exact values of communication quality for non-convergent games has not been recorded for the present simulations, communication quality did always go above chance (with chance in an \nslsg{n} being equal to a ratio of \(\frac{1}{n}\)).

\begin{table}
	\centering
	\begin{tabular}{rllrll}
		\toprule
		\multicolumn{3}{c}{\textsc{sender}} & \multicolumn{3}{c}{\textsc{receiver}} \\
		\cmidrule(lr){1-3}\cmidrule(lr){4-6}
		\# of balls & \citeauthor{barrett_numerical_2006} & mine & \# of balls & \citeauthor{barrett_numerical_2006} & mine \\
		\midrule
		\multicolumn{3}{c}{\emph{state \textsc{a} urn}} & \multicolumn{3}{c}{\emph{signal 0 urn}} \\
		\cmidrule(lr){1-3}\cmidrule(lr){4-6}
		signal 0 & 3      & 1      & act \textsc{a} & 3      & 1 \\
		signal 1 & 333688 & 332968 & act \textsc{b} & 1      & 333599 \\
		signal 2 & 2      & 1      & act \textsc{c} & 333141 & 1 \\
		\midrule
		\multicolumn{3}{c}{\emph{state \textsc{b} urn}} & \multicolumn{3}{c}{\emph{signal 1 urn}} \\
		\cmidrule(lr){1-3}\cmidrule(lr){4-6}
		signal 0 & 1      & 333601 & act \textsc{a} & 333688 & 332971 \\
		signal 1 & 1      & 1      & act \textsc{b} & 1      & 1 \\
		signal 2 & 332514 & 1      & act \textsc{c} & 4      & 1 \\
		\midrule
		\multicolumn{3}{c}{\emph{state \textsc{c} urn}} & \multicolumn{3}{c}{\emph{signal 2 urn}} \\
		\cmidrule(lr){1-3}\cmidrule(lr){4-6}
		signal 0 & 333141 & 1      & act \textsc{a} & 2      & 1 \\
		signal 1 & 4      & 1      & act \textsc{b} & 332514 & 1 \\
		signal 2 & 20     & 333299 & act \textsc{c} & 20     & 333298 \\
		\bottomrule
	\end{tabular}
	\caption{caption}
	\label{tab:urns}
\end{table}

\subsection{Concluding remarks}
\label{ssec:rescon}
The few simulations carried out in the previous subsections are of course only the tip of the iceberg of what the model is capable of.
Throughout the simulations I have kept most of the parameters constant; not because I do not deem them useful, but simply because the time it takes to properly explore the model's entire parameter space is more adequately measured in days than hours.
Consequently, the open space for further exploration of the model is vast.
A desirable discovery would be parameter settings that speed up the convergence towards perfect communication.
In the simulations performed, all parameter changes that deviated from the ``default'' have slowed down the convergence speed.

\section{Discussion}
\label{sec:dis}

\citep{wilensky_netlogo_1999}
\newpage%\twocolumn\recalctypearea
\bibliography{standard}  % insert bibliography
\end{document}